{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import torch.utils as utils\n",
    "import lightning as L\n",
    "from torchmetrics import Precision, Recall, F1Score, AUROC\n",
    "from text_clf_base.data import TextClfDataset\n",
    "from text_clf_base.model import TextClf\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClfDataset(f\"../data/{DATASET}/train_text.txt\", f\"../data/{DATASET}/train_label.txt\")\n",
    "train_loader = utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "_ = iter(train_loader)\n",
    "\n",
    "val_dataset = TextClfDataset(f\"../data/{DATASET}/valid_text.txt\", f\"../data/{DATASET}/valid_label.txt\")\n",
    "val_loader = utils.data.DataLoader(val_dataset, batch_size=32)\n",
    "_ = iter(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClf(train_dataset.tokenizer.get_vocab_size(), d_model=128, num_layers=4, nhead=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type               | Params | In sizes       | Out sizes     \n",
      "--------------------------------------------------------------------------------\n",
      "0 | embed  | Embedding          | 2.7 M  | [32, 128]      | [32, 128, 128]\n",
      "1 | model  | TransformerEncoder | 2.4 M  | [32, 128, 128] | [32, 128, 128]\n",
      "2 | output | Linear             | 129    | [32, 128]      | [32, 1]       \n",
      "--------------------------------------------------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.306    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd485263bac94cb3b1c6acd7709d4b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxonic/miniconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/yxonic/miniconda3/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37a9e0ab06949d09f95fbd8e05afaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6561cd8b4ded4141ae1e37420ffd4334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170173b4fdda42498fc9efbeb4ca4739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "trainer = L.Trainer(max_epochs=2)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall and F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000, Recall: 0.9167, F1 score: 0.9565, AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "precision = Precision('binary')\n",
    "recall = Recall('binary')\n",
    "f1 = F1Score('binary')\n",
    "auc = AUROC('binary')\n",
    "\n",
    "test_dataset = TextClfDataset(f\"../data/{DATASET}/test_text.txt\", f\"../data/{DATASET}/test_label.txt\")\n",
    "test_loader = utils.data.DataLoader(test_dataset, batch_size=64)\n",
    "for x, y in test_loader:\n",
    "    y_score = torch.sigmoid(model(x))\n",
    "    y_pred = y_score > 0.5\n",
    "    precision.update(y_pred, y)\n",
    "    recall.update(y_pred, y)\n",
    "    f1.update(y_pred, y)\n",
    "    auc.update(y_score, y)\n",
    "\n",
    "print(f\"Precision: {precision.compute():.4f}, Recall: {recall.compute():.4f}, F1 score: {f1.compute():.4f}, AUC: {auc.compute():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
